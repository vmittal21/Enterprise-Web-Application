{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import contextlib\n",
    "import datetime\n",
    "import pymysql\n",
    "from surprise import BaselineOnly\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import SVD\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import train_test_split\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "john@gmail.com ['personalcare01', 'medicine01', 'nutrition04']\nrida@gmail.com ['personalcare01', 'vitamin09', 'Magnetic']\njudy@gmail.com ['personalcare01', 'Airstream', 'vitamin08']\nned@gmail.com ['personalcare01', 'BodyScrub', 'Airstream']\nvinc@gmail.com ['medicine01', 'Airstream', 'personalcare01']\nryan@gmail.com ['personalcare01', 'nutrition04', 'Airstream']\nkelly@gmail.com ['homecare06', 'nutrition04', 'homecare01']\nzayn@gmail.com ['vitamin01', 'Airstream', 'Gloves']\nangel@gmail.com ['homecare03', 'personalcare03', 'nutrition04']\nkaylum@gmail.com ['personalcare01', 'nutrition04', 'homecare01']\njessi@gmail.com ['personalcare01', 'homecare06', 'personalcare03']\nliza@gmail.com ['personalcare02', 'nutrition04', 'personalcare01']\n"
     ]
    }
   ],
   "source": [
    "pr_file_path=\"C:/Users/uee85/CSP584HealthHub/WebContent/python/\"\n",
    "\n",
    "TRANSACTION_SQL_QUERY = \"\"\"\n",
    "SELECT login_ID, Product_ID, Review_Rating FROM transactions;\n",
    "\"\"\"\n",
    "connection = pymysql.connect(host='localhost',\n",
    "                             user='root',\n",
    "                             password='1234',\n",
    "                             db='healthhub')\n",
    "\n",
    "with contextlib.closing(connection):\n",
    "    with connection.cursor() as cursor:\n",
    "        cursor.execute(TRANSACTION_SQL_QUERY)\n",
    "        transaction_results = cursor.fetchall()\n",
    "\n",
    "transaction_output_file = 'mysql_train.csv'\n",
    "with open(transaction_output_file, 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile, lineterminator='\\n')\n",
    "    csv_writer.writerows(transaction_results)\n",
    "            \n",
    "file_path = os.path.expanduser(pr_file_path+'/mysql_train.csv')\n",
    "\n",
    "# As we're loading a custom dataset, we need to define a reader. In the\n",
    "# movielens-100k dataset, each line has the following format:\n",
    "# 'user item rating timestamp', separated by '\\t' characters.\n",
    "reader = Reader(line_format='user item rating', sep=',')\n",
    "\n",
    "#data = Dataset.load_from_file(file_path, reader=reader)\n",
    "\n",
    "def get_top_n(predictions, n=10):\n",
    "    '''Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    '''\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n\n",
    "\n",
    "# First train an SVD algorithm on the movielens dataset.\n",
    "data = Dataset.load_from_file(file_path, reader=reader)\n",
    "trainset = data.build_full_trainset()\n",
    "algo = SVD()\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Than predict ratings for all pairs (u, i) that are NOT in the training set.\n",
    "testset = trainset.build_anti_testset()\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "top_n = get_top_n(predictions, n=3)\n",
    "\n",
    "# Print the recommended items for each user\n",
    "for uid, user_ratings in top_n.items():\n",
    "    print(uid, [iid for (iid, _) in user_ratings])\n",
    "    \n",
    "out = open(pr_file_path+'/matrixFactorizationBasedRecommendations.csv', 'w',newline='')\n",
    "output=csv.writer(out)\n",
    "\n",
    "for uid, user_ratings in top_n.items():\n",
    "    output.writerow([uid, [iid for (iid, _) in user_ratings]])\n",
    "    \n",
    "out.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}